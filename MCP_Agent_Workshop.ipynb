{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e88063a7-b8e7-468b-8602-b59a5dcf3223",
   "metadata": {},
   "source": [
    "# Oracle MCP Email Agent Workshop\n",
    "\n",
    "## Building a Document Search and Email Automation Agent\n",
    "\n",
    "### Introduction\n",
    "\n",
    "This notebook demonstrates how to build an agentic email assistant that can search uploaded documents, look up recipients, and automatically draft or send emails using LangChain, Oracle GenAI, and MCP tool integration.\n",
    "\n",
    "**In this workshop, you'll learn:**\n",
    "1. Environment and dependency setup for Oracle, LangChain, and MCP\n",
    "2. How to register and use modular tools through MCP\n",
    "3. How to load, chunk, and embed documents for RAG (Retrieval-Augmented Generation)\n",
    "4. How a GenAI agent orchestrates tool use for complex queries\n",
    "5. How to run everything seamlessly in Jupyter/VS Code\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fae773-5861-45a9-ad17-6a1a2bc53b4a",
   "metadata": {},
   "source": [
    "# Section 1: Environment Setup/ Improrts and Database Connnection\n",
    "\n",
    "We first set up our Python environment and import the necessary libraries, including LangChain components, OracleDB drivers, and the MCP (Modular Command Processor) platform.\n",
    "\n",
    "- We use OracleDB Python drivers, **not** the deprecated `cx_Oracle`, to support vector search.\n",
    "- All tools and configurations are version-controlled and reproducible in this notebook.\n",
    "\n",
    "## Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd805c1b-7203-48cc-ad5b-2f8aa4b1594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "import subprocess\n",
    "from dotenv import load_dotenv\n",
    "from tools9 import DatabaseOperations\n",
    "\n",
    "\n",
    "# Enable nested asyncio loops for Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load .env with Oracle etc.\n",
    "load_dotenv()\n",
    "\n",
    "# (Optional) Silence HuggingFace tokenizer warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd61972-8b4e-441b-814a-fd4f34d0080b",
   "metadata": {},
   "source": [
    "## Oracle Database Connection\n",
    "\n",
    "Connecting to Oracle database using the database username and password which are stored as environment variables (in .env file on linux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa7131b2-02bf-46dd-ab8d-3ea7fb47e16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected!\n"
     ]
    }
   ],
   "source": [
    "db_ops = DatabaseOperations()\n",
    "connected = db_ops.connect()\n",
    "print(\"✅ Connected!\" if connected else \"❌ Connection Failed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e482478-56a7-4691-950c-c8ec1267f360",
   "metadata": {},
   "source": [
    "## 2. Start the MCP Tool Server in the Background\n",
    "\n",
    "Before your notebook can use the agent tools (such as document search, email sending, and recipient lookup), you must start the MCP Tool Server. \n",
    "\n",
    "The MCP Tool Server is responsible for:\n",
    "- Registering all your custom tools (with `@mcp.tool()` decorators)\n",
    "- Handling communication between your notebook’s agent and the available tools\n",
    "\n",
    "**How it works:**\n",
    "- Start the tool server as a separate background process.\n",
    "- The server listens for requests—such as RAG searches, recipient lookups, or email drafts—from your agent running in the notebook.\n",
    "\n",
    "This approach ensures modularity: you can update your tools or restart the server independently of your notebook session.\n",
    "\n",
    "**In this notebook, we will:**\n",
    "- Use Python’s `subprocess` module to launch `server.py` in the background.\n",
    "- Display the server code here for transparency and reproducibility.\n",
    "\n",
    "**Tip:** If you modify your tools in `server.py`, restart the server process to load the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e07def6c-f6d8-47d4-b2ff-d85520b18482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCP server.py started in background with PID 88909\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Start the MCP server in background (make sure server.py is in this folder)\n",
    "server_process = subprocess.Popen(['python', 'server.py'])\n",
    "print(f\"MCP server.py started in background with PID {server_process.pid}\")\n",
    "\n",
    "# Give the server a couple seconds to spin up\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1755a7-75dd-4920-9f21-38b81b0a7e42",
   "metadata": {},
   "source": [
    "## 3. Review the MCP Tool Server Code (`server.py`)\n",
    "\n",
    "To promote transparency and reproducibility, it’s important to inspect the exact code that defines and registers the agent tools used by your MCP server.\n",
    "\n",
    "**What you'll see here:**\n",
    "- All tool registrations (`@mcp.tool()`), such as document chunking, RAG search, recipient lookup, and email functions\n",
    "- Any configuration, imports, or shared state the server uses\n",
    "\n",
    "By including the content of `server.py` directly in this notebook, anyone can understand or audit the logic available to your agent, and you can easily compare versions or document changes during development.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d235c25-d2a7-4fb6-8972-fa0306bc8264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from mcp.server.fastmcp import FastMCP\n",
       "from tools9 import DatabaseOperations, fetch_recipients, send_email_function, extract_email_data_from_response\n",
       "\n",
       "from tools9 import fetch_recipients, send_email_function, chunks_to_docs_wrapper\n",
       "from typing import List\n",
       "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
       "from langchain_core.documents import Document\n",
       "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
       "from langchain_community.vectorstores.utils import DistanceStrategy\n",
       "from langchain_community.vectorstores.oraclevs import OracleVS\n",
       "import os\n",
       "mcp = FastMCP(\"EmailAssistant\")\n",
       "\n",
       "global_vector_store = None\n",
       "\n",
       "def set_vector_store(store: OracleVS):\n",
       "    global global_vector_store\n",
       "    global_vector_store = store\n",
       "\n",
       "\n",
       "def get_vector_store():\n",
       "    global global_vector_store   # ← Add this line\n",
       "    if global_vector_store:\n",
       "        return global_vector_store\n",
       "\n",
       "    \n",
       "    try:\n",
       "        db_ops = DatabaseOperations()\n",
       "        if not db_ops.connect():\n",
       "            raise Exception(\"DB connect failed\")\n",
       "\n",
       "        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
       "\n",
       "        global_vector_store = OracleVS(\n",
       "        embedding_function=embeddings,\n",
       "        client=db_ops.connection,\n",
       "        table_name=\"MY_DEMO4\",\n",
       "        distance_strategy=DistanceStrategy.COSINE,\n",
       "        )\n",
       "        return global_vector_store\n",
       "    except Exception as e:\n",
       "        print(\"VectorStore init failed:\", e)\n",
       "        return None\n",
       "\n",
       "\n",
       "\n",
       "@mcp.tool()\n",
       "def lookup_recipients(name: str):\n",
       "    return fetch_recipients(name)\n",
       "\n",
       "# @mcp.tool()\n",
       "# def prepare_and_send_email(to: str, subject: str, message: str):\n",
       "#     return send_email_function({\"to\": to, \"subject\": subject, \"message\": message})\n",
       "\n",
       "\n",
       "@mcp.tool()\n",
       "def oracle_connect() -> str:\n",
       "    \"\"\"\n",
       "    Checks and returns Oracle DB connection status.\n",
       "    \"\"\"\n",
       "    try:\n",
       "        db_ops = DatabaseOperations()\n",
       "        if db_ops.connect():\n",
       "            print(\"Oracle connection successful!\")\n",
       "            return db_ops.connection\n",
       "        return None\n",
       "    except Exception as e:\n",
       "        print(f\"Oracle connection failed: {str(e)}\")\n",
       "        return None    \n",
       "\n",
       "@mcp.tool()\n",
       "def extract_email_fields_from_response(response_text: str) -> dict:\n",
       "    \"\"\"\n",
       "    Extracts email fields (to, subject, message) from an AI-generated response.\n",
       "\n",
       "    Input:\n",
       "    - response_text: A string containing the AI assistant's output.\n",
       "\n",
       "    Output:\n",
       "    - A dictionary with keys: \"to\", \"subject\", \"message\"\n",
       "    \"\"\"\n",
       "    try:\n",
       "        return extract_email_data_from_response(response_text)\n",
       "    except Exception as e:\n",
       "        return {\"error\": f\"Failed to extract email data: {str(e)}\"}\n",
       "\n",
       "\n",
       "@mcp.tool()\n",
       "def store_text_chunks(file_path: str) -> str:\n",
       "    \"\"\"Split text and store as embeddings in Oracle Vector Store\"\"\"\n",
       "    try:\n",
       "        db_ops = DatabaseOperations()\n",
       "        \n",
       "        if not db_ops.connect():\n",
       "            return \"❌ Oracle connection failed.\"\n",
       "\n",
       "        with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
       "            raw_text = f.read()\n",
       "\n",
       "            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
       "            chunks = text_splitter.split_text(raw_text)\n",
       "            file_name = os.path.basename(file_path)\n",
       "            docs = [\n",
       "                chunks_to_docs_wrapper({'id': f\"{file_name}_{i}\", 'link': f\"{file_name} - Chunk {i}\", 'text': chunk})\n",
       "                for i, chunk in enumerate(chunks)\n",
       "            ]\n",
       "\n",
       "\n",
       "            embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
       "            vector_store = OracleVS.from_documents(\n",
       "                docs, embeddings, client=db_ops.connection,\n",
       "                table_name=\"MY_DEMO4\", distance_strategy=DistanceStrategy.COSINE)\n",
       "            \n",
       "            # OracleVS(\n",
       "            #     embedding_function=embeddings,\n",
       "            #     client=db_ops.connection,\n",
       "            #     table_name=\"MY_DEMO4\",\n",
       "            #     distance_strategy=DistanceStrategy.COSINE,\n",
       "            # )\n",
       "\n",
       "            set_vector_store(vector_store)\n",
       "\n",
       "            return f\"✅ Stored {len(docs)} chunks from {file_name}\"\n",
       "\n",
       "    except Exception as e:\n",
       "        return f\"❌ Error: {str(e)}\"\n",
       "\n",
       "@mcp.tool()\n",
       "def rag_search(query: str) -> str:\n",
       "    \"\"\"\n",
       "    Retrieve relevant information from user-uploaded documents stored in the Oracle Vector Store.\n",
       "\n",
       "    Use this tool whenever a user asks a question that may be answered from the uploaded documents\n",
       "    (e.g., HR policy files, contracts, technical manuals, PDF uploads, etc.).\n",
       "\n",
       "    The tool performs a semantic similarity search over the embedded document chunks and returns\n",
       "    the top 5 most relevant text snippets.\n",
       "\n",
       "    Input:\n",
       "    - A natural language question or topic from the user.\n",
       "\n",
       "    Output:\n",
       "    - A formatted string combining the most relevant document excerpts.\n",
       "\n",
       "    Examples:\n",
       "    - \"What is the leave policy for new employees?\"\n",
       "    - \"Summarize the refund terms in the uploaded contract\"\n",
       "    - \"Find safety precautions mentioned in the manual\"\n",
       "    \"\"\"\n",
       "    try:\n",
       "        # Load vector store (or access from persistent source if needed)\n",
       "        vector_store = get_vector_store()\n",
       "        if vector_store is None:\n",
       "            return \"❌ No documents have been indexed yet.\"\n",
       "\n",
       "        docs = vector_store.similarity_search(query, k=5)\n",
       "        return \"\\n\".join([doc.page_content for doc in docs])\n",
       "    except Exception as e:\n",
       "        return f\"❌ Error during document search: {str(e)}\"\n",
       "\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "\n",
       "    print(\"Starting MCP Agentic Server...\")\n",
       "    mcp.run(transport=\"stdio\")\n",
       "\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "with open(\"server.py\", \"r\") as f:\n",
    "    server_code = f.read()\n",
    "display(Markdown(f\"```python\\n{server_code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67084f5-3eae-41b4-8ae8-a0fefa7671cb",
   "metadata": {},
   "source": [
    "## 4. MCP Agent & GenAI Setup\n",
    "\n",
    "Now that the MCP Tool Server is running and our tools are registered, we'll set up the intelligent agent that will use these tools to solve user queries.\n",
    "\n",
    "**What happens in this step:**\n",
    "- Connect securely to the running MCP Tool Server from within the notebook.\n",
    "- Dynamically retrieve the latest version of all registered tools (such as `rag_search`, recipient lookup, and email functions).\n",
    "- Initialize a powerful GenAI (Generative AI) large language model (LLM) to act as the agent's reasoning engine.\n",
    "- Combine the tools and LLM into an agentic workflow: the GenAI agent will understand user prompts, plan which tools to use, and execute complex tasks automatically.\n",
    "\n",
    "This architecture allows the agent to orchestrate multiple tools seamlessly—retrieving documents, summarizing content, finding recipients, and drafting or sending emails—all based on natural language prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55eb6e28-5d5b-47db-956c-bd7f6923adda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# Set up the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# This param is required by the package, but since our server is already running, we'll set connect=False below\n",
    "server_params = StdioServerParameters(command=\"python\", args=[\"server.py\"])\n",
    "\n",
    "async def run_mcp_agent(prompt):\n",
    "    # Connect to the already-launched MCP tool server (stdin/stdout)\n",
    "    async with stdio_client(server_params) as (read, write):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            await session.initialize()\n",
    "            tools = await load_mcp_tools(session)\n",
    "            agent = create_react_agent(llm, tools)\n",
    "            response = await agent.ainvoke({\n",
    "                \"messages\": [HumanMessage(prompt)]\n",
    "            })\n",
    "            return response[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87feed3a-9952-46d2-863f-9b061119b407",
   "metadata": {},
   "source": [
    "## 5. Index a Test Document\n",
    "\n",
    "To enable document search and retrieval-augmented generation (RAG), the agent requires access to relevant documents that have been chunked and embedded in the Oracle Vector Store.\n",
    "\n",
    "**In this step:**\n",
    "- We'll create (or upload) a sample policy document.\n",
    "- The agent will use the corresponding MCP tool (for example, `store_text_chunks`) to split the document into manageable text chunks and store their semantic embeddings in the Oracle DB vector store.\n",
    "- These embeddings will enable fast, accurate semantic search when querying for information later.\n",
    "\n",
    "Storing documents in this way allows our agent to understand and answer questions based on actual company policies, contracts, manuals, or any other proprietary documents you choose to index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "295c38db-f6fc-45d6-a959-244cfbdce28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created sample policy document with 187 words at: sample_policy.txt\n",
      "Please provide the document \"sample_policy.txt\" so that I can proceed with indexing it.\n"
     ]
    }
   ],
   "source": [
    "# Create a simple policy file\n",
    "test_file_path = \"sample_policy.txt\"\n",
    "policy_text = \"\"\"\n",
    "EMPLOYEE LEAVE POLICY (v2023)\n",
    "\n",
    "SECTION 1: ANNUAL LEAVE ENTITLEMENTS\n",
    "\n",
    "1.1 All full-time employees are entitled to 15 working days of paid annual leave per calendar year.\n",
    "1.2 Leave accrues at a rate of 1.25 days per month of service.\n",
    "1.3 Maximum carryover of unused leave is 5 days into the next calendar year.\n",
    "\n",
    "SECTION 2: SICK LEAVE\n",
    "\n",
    "2.1 Employees receive 10 days of paid sick leave annually.\n",
    "2.2 Medical certificate required for absences exceeding 3 consecutive days.\n",
    "2.3 Unused sick leave does not carry over to the next year.\n",
    "\n",
    "SECTION 3: PARENTAL LEAVE\n",
    "\n",
    "3.1 Maternity leave: 12 weeks paid leave for new mothers.\n",
    "3.2 Paternity leave: 4 weeks paid leave for new fathers.\n",
    "3.3 Adoption leave: 8 weeks paid leave for adoptive parents.\n",
    "\n",
    "SECTION 4: SPECIAL CIRCUMSTANCES\n",
    "\n",
    "4.1 Bereavement leave: 5 days for immediate family members.\n",
    "4.2 Jury duty: Full pay for duration of service.\n",
    "4.3 Military leave: Protected unpaid leave for reservists.\n",
    "\n",
    "CONTACT INFORMATION:\n",
    "\n",
    "- HR Department: hr@company.com\n",
    "- Leave Requests: leave@company.com\n",
    "- Emergency Contact: +1 (555) 123-4567\n",
    "\n",
    "POLICY UPDATES:\n",
    "\n",
    "This policy is reviewed annually. Last updated: January 2023.\n",
    "For interpretation questions, contact the HR Director.\n",
    "\"\"\"\n",
    "\n",
    "with open(test_file_path, \"w\") as f:\n",
    "    f.write(policy_text)\n",
    "\n",
    "print(f\"Created sample policy document with {len(policy_text.split())} words at: {test_file_path}\")\n",
    "\n",
    "with open(test_file_path, \"w\") as f:\n",
    "    f.write(\"Employees are entitled to 15 days annual leave. For more details, contact HR at hr@company.com.\")\n",
    "\n",
    "# Ask the MCP agent to index the file using the document chunking tool\n",
    "result = await run_mcp_agent(f\"Please index this document: {test_file_path}\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a4c489-6915-430a-bd5a-d21aa29efda8",
   "metadata": {},
   "source": [
    "## 6. Run an End-to-End Agent Example\n",
    "\n",
    "In this step, you’ll see the full power of the GenAI agent in action:  \n",
    "By providing a single natural language prompt, the agent will:\n",
    "\n",
    "1. Use the MCP tools to query the indexed documents (via semantic search/RAG),\n",
    "2. Summarize the relevant information,\n",
    "3. Lookup the recipient’s details as needed,\n",
    "4. And automatically draft and (optionally) send an email with the findings.\n",
    "\n",
    "This demonstrates true agentic orchestration:  \n",
    "The system transparently selects and invokes multiple tools, combining their outputs to fulfill a complex, real-world workflow—all from a single user request.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f31c781a-d671-4b40-aea7-7b110e456e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGENT RESPONSE:\n",
      " I have extracted the email fields for you:\n",
      "\n",
      "- **To:** hr@company.com\n",
      "- **Subject:** Information\n",
      "- **Message:** Please email HR with the following summary of the leave policy: Employees are entitled to 15 days annual leave. For more details, contact HR at hr@company.com.\n",
      "\n",
      "You can now send this email to HR.\n"
     ]
    }
   ],
   "source": [
    "user_query = (\n",
    "    \"Find the leave policy from the indexed documents and email HR with the summary.\"\n",
    ")\n",
    "result = await run_mcp_agent(user_query)\n",
    "print(\"AGENT RESPONSE:\\n\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44578ace-34a0-4a6c-8414-a82246b27333",
   "metadata": {},
   "source": [
    "## 7. Try RAG, Recipient Lookup, & Email Drafts\n",
    "\n",
    "Now let's interactively test the core MCP tools that power our GenAI agent:\n",
    "\n",
    "- **RAG Search:** Extract answers to company-specific questions from your indexed policy documents using Retrieval-Augmented Generation (RAG).\n",
    "- **Recipient Lookup:** Quickly find the email address or contact info for team members or departments (e.g., \"HR\").\n",
    "- **Email Drafting:** Automatically generate email drafts that summarize or forward policies and insights to the right recipients.\n",
    "\n",
    "In this section, you'll run prompts that directly demonstrate each tool's capability.  \n",
    "You'll see how the agent seamlessly orchestrates document search and business communication—all enabled by your modular MCP tool framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9a23b4e-c3f4-4a04-991d-16b0936a3fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "RAG Search Example:\n",
      "The leave policy entitles employees to 15 days of annual leave. For more detailed information, you can contact HR at hr@company.com.\n",
      "---\n",
      "Recipient Lookup Example:\n",
      "The email for Ashu is ashu.kumar@oracle.com.\n",
      "---\n",
      "Email Draft Example:\n",
      "Here's a draft email about the annual leave policy for Ashu:\n",
      "\n",
      "---\n",
      "\n",
      "**To:** ashu.kumar@oracle.com\n",
      "\n",
      "**Subject:** Update on Annual Leave Policy\n",
      "\n",
      "Hi Ashu,\n",
      "\n",
      "I hope this message finds you well. I wanted to inform you about the recent updates to our annual leave policy. Please find the details below:\n",
      "\n",
      "1. All employees are entitled to 20 days of paid annual leave per year.\n",
      "2. Leave must be scheduled in advance and approved by your manager.\n",
      "3. Unused leave days can be carried over to the next year, up to a maximum of 10 days.\n",
      "4. For any leave exceeding 5 consecutive days, a formal request must be submitted.\n",
      "\n",
      "Please let me know if you have any questions or need further clarification.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "print(\"---\\nRAG Search Example:\")\n",
    "result = await run_mcp_agent(\"What is the leave policy?\")\n",
    "print(result)\n",
    "\n",
    "print(\"---\\nRecipient Lookup Example:\")\n",
    "result = await run_mcp_agent(\"Find the email for Ashu.\")\n",
    "print(result)\n",
    "\n",
    "print(\"---\\nEmail Draft Example:\")\n",
    "result = await run_mcp_agent(\"Send a draft email about annual leave policy to Ashu.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fb91f7-e883-44d7-8308-9af9036a6590",
   "metadata": {},
   "source": [
    "## 8. Show Oracle/GenAI Features via RAG\n",
    "\n",
    "A powerful advantage of this agentic architecture is the ability to surface product or policy features directly from your indexed documents using semantic search and GenAI summarization.\n",
    "\n",
    "**In this step:**\n",
    "- You’ll ask the agent to list key features of Oracle 23ai (or any product, policy, or technical topic you’ve indexed).\n",
    "- The agent will use the RAG (Retrieval-Augmented Generation) tool to retrieve relevant document chunks and synthesize a summary, ensuring the response is both accurate and grounded in your actual content.\n",
    "\n",
    "This capability is ideal for:\n",
    "- Quickly briefing users on new software features\n",
    "- Surfacing business policy changes\n",
    "- Enabling dynamic, context-aware onboarding and knowledge management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e72f00d-d313-4e85-8647-c06f10936cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems that the document search returned information unrelated to Oracle 23ai features. Please ensure that the relevant documents are uploaded and indexed, or provide more specific details about the features you are interested in.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"List 5 new features of Oracle 23ai from the indexed documents.\"\n",
    "result = await run_mcp_agent(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8387dc-f41d-498a-b5a1-01b29a955c09",
   "metadata": {},
   "source": [
    "## 9. Shut Down MCP Server\n",
    "\n",
    "When you’re finished using the agent and running notebook experiments, it’s important to stop the background MCP Tool Server process you started earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4d55fce-6bc0-488b-9b03-f0cac400baec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped MCP server process.\n"
     ]
    }
   ],
   "source": [
    "server_process.terminate()\n",
    "print(\"Stopped MCP server process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80543fa-6463-411d-a2a6-d0df7eeeff38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
