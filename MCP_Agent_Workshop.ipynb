{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e88063a7-b8e7-468b-8602-b59a5dcf3223",
   "metadata": {},
   "source": [
    "# Oracle MCP Agent Workshop\n",
    "\n",
    "## Building Agentic Workflows with the Model Context Protocol (MCP)\n",
    "\n",
    "### Introduction\n",
    "\n",
    "This notebook demonstrates how to build a modular, enterprise-grade email assistant using the **Oracle Model Context Protocol (MCP)** as the backbone for all agent-tool orchestration. MCP empowers you to decouple business logic into reusable \"tools\" that are securely registered and dynamically accessed by GenAI agents.\n",
    "\n",
    "**With MCP, your agents can:**\n",
    "- Search and summarize organization-specific documents through Retrieval-Augmented Generation (RAG)\n",
    "- Look up email recipients from authoritative company directories\n",
    "- Draft, send, and manage emails—all via orchestrated tool calls rather than hardcoded logic\n",
    "\n",
    "**In this workshop, you'll learn how to:**\n",
    "1. Set up a robust, MCP-based environment for scalable agent workflows using Oracle, LangChain, and MCP\n",
    "2. Register custom business and document tools using the MCP Tool Server (`@mcp.tool`)\n",
    "3. Connect notebooks and applications to the MCP Tool Server, enabling dynamic discovery and invocation of registered tools\n",
    "4. Perform advanced document ingestion, semantic search, and retrieval using RAG—all as MCP tools\n",
    "5. Orchestrate complex, multi-step tasks via MCP by combining GenAI agent planning with enterprise automation tools\n",
    "\n",
    "Throughout this notebook, every agent action is backed by the Model Context Protocol (MCP), ensuring modularity, transparency, and ease of extension as your enterprise needs evolve.\n",
    "\n",
    "Let's get started with MCP!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fae773-5861-45a9-ad17-6a1a2bc53b4a",
   "metadata": {},
   "source": [
    "# Section 1: Environment Setup/ Improrts and Database Connnection\n",
    "\n",
    "We first set up our Python environment and import the necessary libraries, including LangChain components, OracleDB drivers, and the MCP (Modular Command Processor) platform.\n",
    "\n",
    "- We use OracleDB Python drivers, **not** the deprecated `cx_Oracle`, to support vector search.\n",
    "- All tools and configurations are version-controlled and reproducible in this notebook.\n",
    "\n",
    "## Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd805c1b-7203-48cc-ad5b-2f8aa4b1594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "import subprocess\n",
    "from dotenv import load_dotenv\n",
    "from tools9 import DatabaseOperations\n",
    "\n",
    "\n",
    "# Enable nested asyncio loops for Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load .env with Oracle etc.\n",
    "load_dotenv()\n",
    "\n",
    "# (Optional) Silence HuggingFace tokenizer warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd61972-8b4e-441b-814a-fd4f34d0080b",
   "metadata": {},
   "source": [
    "## Oracle Database Connection\n",
    "\n",
    "Connecting to Oracle database using the database username and password which are stored as environment variables (in .env file on linux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa7131b2-02bf-46dd-ab8d-3ea7fb47e16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected!\n"
     ]
    }
   ],
   "source": [
    "db_ops = DatabaseOperations()\n",
    "connected = db_ops.connect()\n",
    "print(\"✅ Connected!\" if connected else \"❌ Connection Failed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e482478-56a7-4691-950c-c8ec1267f360",
   "metadata": {},
   "source": [
    "## 2. Start the MCP Tool Server in the Background\n",
    "\n",
    "Before your GenAI agent can access any tools, you must start the **MCP Tool Server**, which acts as a registry and secure communication bridge between your modular tools and any client (notebooks, apps, or agents). With MCP, you can update, restart, or extend your tool ecosystem independently of your agent logic. This ensures that as team or enterprise needs change, your agents always have access to the latest, most reliable automation tools.\n",
    "\n",
    "The MCP Tool Server is responsible for:\n",
    "- Registering all your custom tools (with `@mcp.tool()` decorators)\n",
    "- Handling communication between your notebook’s agent and the available tools\n",
    "\n",
    "**How it works:**\n",
    "- Start the tool server as a separate background process.\n",
    "- The server listens for requests—such as RAG searches, recipient lookups, or email drafts—from your agent running in the notebook.\n",
    "\n",
    "This approach ensures modularity: you can update your tools or restart the server independently of your notebook session.\n",
    "\n",
    "**In this notebook, we will:**\n",
    "- Use Python’s `subprocess` module to launch `server.py` in the background.\n",
    "- Display the server code here for transparency and reproducibility.\n",
    "\n",
    "**Tip:** If you modify your tools in `server.py`, restart the server process to load the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e07def6c-f6d8-47d4-b2ff-d85520b18482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCP server.py started in background with PID 57337\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "python_path = sys.executable  # dynamically picks current kernel's Python path\n",
    "server_process = subprocess.Popen([python_path, 'server.py'])\n",
    "\n",
    "print(f\"MCP server.py started in background with PID {server_process.pid}\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1755a7-75dd-4920-9f21-38b81b0a7e42",
   "metadata": {},
   "source": [
    "## 3. Review Your MCP Tool Server (`server.py`)\n",
    "\n",
    "With MCP, all tools are explicitly registered and auditable. Here, we'll inspect the code that defines and registers each modular tool—such as `rag_search`, `lookup_recipients`, and email orchestration—ensuring every step in the agent workflow is driven by a transparent, MCP-managed contract between code and agent.\n",
    "\n",
    "This practice is central to MCP: tools are not just functions, but versioned, documented, testable building blocks discoverable at runtime by any MCP-compatible agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d235c25-d2a7-4fb6-8972-fa0306bc8264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from mcp.server.fastmcp import FastMCP\n",
       "from tools9 import DatabaseOperations, fetch_recipients, send_email_function, extract_email_data_from_response\n",
       "\n",
       "from tools9 import fetch_recipients, send_email_function, chunks_to_docs_wrapper\n",
       "from typing import List\n",
       "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
       "from langchain_core.documents import Document\n",
       "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
       "from langchain_community.vectorstores.utils import DistanceStrategy\n",
       "from langchain_community.vectorstores.oraclevs import OracleVS\n",
       "import os\n",
       "mcp = FastMCP(\"EmailAssistant\")\n",
       "\n",
       "global_vector_store = None\n",
       "\n",
       "def set_vector_store(store: OracleVS):\n",
       "    global global_vector_store\n",
       "    global_vector_store = store\n",
       "\n",
       "\n",
       "def get_vector_store():\n",
       "    global global_vector_store   # ← Add this line\n",
       "    if global_vector_store:\n",
       "        return global_vector_store\n",
       "\n",
       "    \n",
       "    try:\n",
       "        db_ops = DatabaseOperations()\n",
       "        if not db_ops.connect():\n",
       "            raise Exception(\"DB connect failed\")\n",
       "\n",
       "        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
       "\n",
       "        global_vector_store = OracleVS(\n",
       "        embedding_function=embeddings,\n",
       "        client=db_ops.connection,\n",
       "        table_name=\"MY_DEMO4\",\n",
       "        distance_strategy=DistanceStrategy.COSINE,\n",
       "        )\n",
       "        return global_vector_store\n",
       "    except Exception as e:\n",
       "        print(\"VectorStore init failed:\", e)\n",
       "        return None\n",
       "\n",
       "\n",
       "\n",
       "@mcp.tool()\n",
       "def lookup_recipients(name: str):\n",
       "    return fetch_recipients(name)\n",
       "\n",
       "# @mcp.tool()\n",
       "# def prepare_and_send_email(to: str, subject: str, message: str):\n",
       "#     return send_email_function({\"to\": to, \"subject\": subject, \"message\": message})\n",
       "\n",
       "\n",
       "@mcp.tool()\n",
       "def oracle_connect() -> str:\n",
       "    \"\"\"\n",
       "    Checks and returns Oracle DB connection status.\n",
       "    \"\"\"\n",
       "    try:\n",
       "        db_ops = DatabaseOperations()\n",
       "        if db_ops.connect():\n",
       "            print(\"Oracle connection successful!\")\n",
       "            return db_ops.connection\n",
       "        return None\n",
       "    except Exception as e:\n",
       "        print(f\"Oracle connection failed: {str(e)}\")\n",
       "        return None    \n",
       "\n",
       "@mcp.tool()\n",
       "def extract_email_fields_from_response(response_text: str) -> dict:\n",
       "    \"\"\"\n",
       "    Extracts email fields (to, subject, message) from an AI-generated response.\n",
       "\n",
       "    Input:\n",
       "    - response_text: A string containing the AI assistant's output.\n",
       "\n",
       "    Output:\n",
       "    - A dictionary with keys: \"to\", \"subject\", \"message\"\n",
       "    \"\"\"\n",
       "    try:\n",
       "        return extract_email_data_from_response(response_text)\n",
       "    except Exception as e:\n",
       "        return {\"error\": f\"Failed to extract email data: {str(e)}\"}\n",
       "\n",
       "\n",
       "@mcp.tool()\n",
       "def store_text_chunks(file_path: str) -> str:\n",
       "    \"\"\"Split text and store as embeddings in Oracle Vector Store\"\"\"\n",
       "    try:\n",
       "        db_ops = DatabaseOperations()\n",
       "        \n",
       "        if not db_ops.connect():\n",
       "            return \"❌ Oracle connection failed.\"\n",
       "\n",
       "        with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
       "            raw_text = f.read()\n",
       "\n",
       "            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
       "            chunks = text_splitter.split_text(raw_text)\n",
       "            file_name = os.path.basename(file_path)\n",
       "            docs = [\n",
       "                chunks_to_docs_wrapper({'id': f\"{file_name}_{i}\", 'link': f\"{file_name} - Chunk {i}\", 'text': chunk})\n",
       "                for i, chunk in enumerate(chunks)\n",
       "            ]\n",
       "\n",
       "\n",
       "            embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
       "            vector_store = OracleVS.from_documents(\n",
       "                docs, embeddings, client=db_ops.connection,\n",
       "                table_name=\"MY_DEMO4\", distance_strategy=DistanceStrategy.COSINE)\n",
       "            \n",
       "            # OracleVS(\n",
       "            #     embedding_function=embeddings,\n",
       "            #     client=db_ops.connection,\n",
       "            #     table_name=\"MY_DEMO4\",\n",
       "            #     distance_strategy=DistanceStrategy.COSINE,\n",
       "            # )\n",
       "\n",
       "            set_vector_store(vector_store)\n",
       "\n",
       "            return f\"✅ Stored {len(docs)} chunks from {file_name}\"\n",
       "\n",
       "    except Exception as e:\n",
       "        return f\"❌ Error: {str(e)}\"\n",
       "\n",
       "@mcp.tool()\n",
       "def rag_search(query: str) -> str:\n",
       "    \"\"\"\n",
       "    Retrieve relevant information from user-uploaded documents stored in the Oracle Vector Store.\n",
       "\n",
       "    Use this tool whenever a user asks a question that may be answered from the uploaded documents\n",
       "    (e.g., HR policy files, contracts, technical manuals, PDF uploads, etc.).\n",
       "\n",
       "    The tool performs a semantic similarity search over the embedded document chunks and returns\n",
       "    the top 5 most relevant text snippets.\n",
       "\n",
       "    Input:\n",
       "    - A natural language question or topic from the user.\n",
       "\n",
       "    Output:\n",
       "    - A formatted string combining the most relevant document excerpts.\n",
       "\n",
       "    Examples:\n",
       "    - \"What is the leave policy for new employees?\"\n",
       "    - \"Summarize the refund terms in the uploaded contract\"\n",
       "    - \"Find safety precautions mentioned in the manual\"\n",
       "    \"\"\"\n",
       "    try:\n",
       "        # Load vector store (or access from persistent source if needed)\n",
       "        vector_store = get_vector_store()\n",
       "        if vector_store is None:\n",
       "            return \"❌ No documents have been indexed yet.\"\n",
       "\n",
       "        docs = vector_store.similarity_search(query, k=5)\n",
       "        return \"\\n\".join([doc.page_content for doc in docs])\n",
       "    except Exception as e:\n",
       "        return f\"❌ Error during document search: {str(e)}\"\n",
       "\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    print(\" Starting MCP Agentic Server ...\")\n",
       "    mcp.run(transport=\"stdio\")\n",
       "\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "with open(\"server.py\", \"r\") as f:\n",
    "    server_code = f.read()\n",
    "display(Markdown(f\"```python\\n{server_code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67084f5-3eae-41b4-8ae8-a0fefa7671cb",
   "metadata": {},
   "source": [
    "## 4. MCP Agent & GenAI Setup\n",
    "\n",
    "Once your MCP Tool Server is running, agents and notebooks connect to it to dynamically discover and access your suite of tools.\n",
    "\n",
    "Here, we pair a large language model (LLM) with the Model Context Protocol to enable agents that not only chat, but autonomously plan and execute multi-step business workflows—by invoking your modular MCP tools based on language, context, and user goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55eb6e28-5d5b-47db-956c-bd7f6923adda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# Set up the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# This param is required by the package, but since our server is already running, we'll set connect=False below\n",
    "server_params = StdioServerParameters(command=\"python\", args=[\"server.py\"])\n",
    "\n",
    "async def run_mcp_agent(prompt):\n",
    "    # Connect to the already-launched MCP tool server (stdin/stdout)\n",
    "    async with stdio_client(server_params) as (read, write):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            await session.initialize()\n",
    "            tools = await load_mcp_tools(session)\n",
    "            agent = create_react_agent(llm, tools)\n",
    "            response = await agent.ainvoke({\n",
    "                \"messages\": [HumanMessage(prompt)]\n",
    "            })\n",
    "            return response[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87feed3a-9952-46d2-863f-9b061119b407",
   "metadata": {},
   "source": [
    "## 5. Index a Test Document via MCP Tool\n",
    "\n",
    "MCP treats every operation—document ingestion, RAG search, email sending—as a tool. Even document indexing is performed through a registered MCP tool, ensuring a unified interface for all automation steps. This design makes it easy to add, update, or re-use business logic across workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "295c38db-f6fc-45d6-a959-244cfbdce28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file `sample_policy.txt` has been successfully indexed and stored as 2 chunks. If you have any questions or need further assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# Create a simple policy file\n",
    "test_file_path = \"sample_policy.txt\"\n",
    "\n",
    "# Ask the MCP agent to index the file using the document chunking tool\n",
    "response = await run_mcp_agent(\"\"\"\n",
    "Please index the file sample_policy.txt placed in the current directory.\n",
    "\"\"\")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a4c489-6915-430a-bd5a-d21aa29efda8",
   "metadata": {},
   "source": [
    "## 6. Run an End-to-End Agentic Workflow with MCP\n",
    "\n",
    "Providing a single natural-language prompt, the GenAI agent—using MCP—remotely discovers, plans, and executes a multi-tool workflow. MCP ensures each invocation, whether for document search or business communication, is managed and auditable, making your agent trustworthy, extensible, and enterprise-ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f31c781a-d671-4b40-aea7-7b110e456e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGENT RESPONSE:\n",
      " It seems I couldn't find a specific email address for the HR department in the system. However, based on the document, you can send the email to `hr@company.com`. Here's the email content you can use:\n",
      "\n",
      "---\n",
      "\n",
      "**Subject:** Summary of Employee Leave Policy\n",
      "\n",
      "**To:** hr@company.com\n",
      "\n",
      "Dear HR Team,\n",
      "\n",
      "I hope this message finds you well. I am writing to provide a summary of the current Employee Leave Policy as per the latest document review:\n",
      "\n",
      "1. **Annual Leave**: Full-time employees are entitled to 15 working days of paid annual leave per year, accruing at 1.25 days per month. A maximum of 5 unused days can be carried over to the next year.\n",
      "\n",
      "2. **Sick Leave**: Employees receive 10 days of paid sick leave annually, with a medical certificate required for absences over 3 consecutive days. Unused sick leave does not carry over.\n",
      "\n",
      "3. **Parental Leave**: Maternity leave is 12 weeks paid, paternity leave is 4 weeks paid, and adoption leave is 8 weeks paid.\n",
      "\n",
      "4. **Special Circumstances**: Includes 5 days of bereavement leave for immediate family, full pay for jury duty, and protected unpaid leave for military service.\n",
      "\n",
      "Please let me know if there are any updates or additional details required.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n",
      "\n",
      "---\n",
      "\n",
      "Feel free to replace `[Your Name]` with your actual name before sending the email.\n"
     ]
    }
   ],
   "source": [
    "user_query = (\n",
    "    \"Find the leave policy from the indexed documents and email HR with the summary.\"\n",
    ")\n",
    "result = await run_mcp_agent(user_query)\n",
    "print(\"AGENT RESPONSE:\\n\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44578ace-34a0-4a6c-8414-a82246b27333",
   "metadata": {},
   "source": [
    "## 7. MCP Tool Demonstrations: RAG, Recipient Lookup, & Email Drafts\n",
    "\n",
    "In this section, you'll directly experience the power of MCP as a modular orchestration layer for enterprise workflows.\n",
    "\n",
    "- **RAG Search via MCP:** The agent leverages a registered MCP tool to perform Retrieval-Augmented Generation, sourcing accurate answers from your indexed organizational data—no direct coding required!\n",
    "- **Recipient Lookup via MCP:** Using MCP’s tool abstraction, agents can securely and reliably query up-to-date company directory information from a single source of truth.\n",
    "- **Email Automation via MCP Toolchain:** Thanks to MCP, email drafting and sending is abstracted into a robust, reusable tool—invocable by any compliant agent with proper permissions.\n",
    "\n",
    "In your prompts, you're not just querying a language model—you're activating powerful, encapsulated automation via the Model Context Protocol tool network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9a23b4e-c3f4-4a04-991d-16b0936a3fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "RAG Search Example:\n",
      "The leave policy includes the following key sections:\n",
      "\n",
      "### Annual Leave Entitlements\n",
      "- **Full-time employees** are entitled to 15 working days of paid annual leave per calendar year.\n",
      "- Leave accrues at a rate of 1.25 days per month of service.\n",
      "- A maximum of 5 unused leave days can be carried over to the next calendar year.\n",
      "\n",
      "### Sick Leave\n",
      "- Employees receive 10 days of paid sick leave annually.\n",
      "- A medical certificate is required for absences exceeding 3 consecutive days.\n",
      "- Unused sick leave does not carry over to the next year.\n",
      "\n",
      "### Parental Leave\n",
      "- **Maternity Leave**: 12 weeks paid leave for new mothers.\n",
      "- **Paternity Leave**: 4 weeks paid leave for new fathers.\n",
      "- **Adoption Leave**: 8 weeks paid leave for adoptive parents.\n",
      "\n",
      "### Special Circumstances\n",
      "- **Bereavement Leave**: 5 days for immediate family members.\n",
      "- **Jury Duty**: Full pay for the duration of service.\n",
      "- **Military Leave**: Protected unpaid leave for reservists.\n",
      "\n",
      "### Contact Information\n",
      "- **HR Department**: hr@company.com\n",
      "- **Leave Requests**: leave@company.com\n",
      "- **Emergency Contact**: +1 (555) 123-4567\n",
      "\n",
      "This policy is reviewed annually and was last updated in January 2023. For any questions regarding the interpretation of this policy, you can contact the HR Director.\n",
      "---\n",
      "Recipient Lookup Example:\n",
      "The email for Ashu is ashu.kumar@oracle.com.\n",
      "---\n",
      "Email Draft Example:\n",
      "Here's a draft email about the annual leave policy for Ashu:\n",
      "\n",
      "- **To:** ashu.kumar@oracle.com\n",
      "- **Subject:** Update on Annual Leave Policy\n",
      "- **Message:**\n",
      "\n",
      "  ```\n",
      "  Hi Ashu,\n",
      "\n",
      "  I hope this message finds you well. I wanted to inform you about the recent updates to our annual leave policy. Please review the attached document for detailed information.\n",
      "\n",
      "  If you have any questions or need further clarification, feel free to reach out.\n",
      "\n",
      "  Best regards,\n",
      "\n",
      "  [Your Name]\n",
      "  ```\n",
      "\n",
      "Let me know if you need any changes or if you would like to send it.\n"
     ]
    }
   ],
   "source": [
    "print(\"---\\nRAG Search Example:\")\n",
    "result = await run_mcp_agent(\"What is the leave policy?\")\n",
    "print(result)\n",
    "\n",
    "print(\"---\\nRecipient Lookup Example:\")\n",
    "result = await run_mcp_agent(\"Find the email for Ashu.\")\n",
    "print(result)\n",
    "\n",
    "print(\"---\\nEmail Draft Example:\")\n",
    "result = await run_mcp_agent(\"Send a draft email about annual leave policy to Ashu.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fb91f7-e883-44d7-8308-9af9036a6590",
   "metadata": {},
   "source": [
    "## 8. Demonstrate Domain Expertise Extraction via RAG & MCP\n",
    "\n",
    "The Model Context Protocol doesn't just automate steps—it lets you encode, evolve, and reuse domain knowledge as tools. With MCP, your agent can surface key product, technical, or policy features directly from live document data using RAG and summarization—all through the modular MCP interface.\n",
    "\n",
    "This capability is critical for:\n",
    "- Delivering expert answers grounded in real company content\n",
    "- Breaking silos so every user can access up-to-date enterprise knowledge via MCP-driven agents\n",
    "- Setting the foundation for AI-powered onboarding, training, and decision support—all orchestrated through MCP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e72f00d-d313-4e85-8647-c06f10936cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The search did not return relevant information about the new features of Oracle 23ai. If you have specific documents or details about Oracle 23ai, please provide them, or I can attempt another search with different parameters.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"List 5 new features of Oracle 23ai from the indexed documents.\"\n",
    "result = await run_mcp_agent(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8387dc-f41d-498a-b5a1-01b29a955c09",
   "metadata": {},
   "source": [
    "## 9. Shutting Down the MCP Tool Server\n",
    "\n",
    "When you're finished running experiments or workflows, it’s important to terminate the MCP Tool Server initialized earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4d55fce-6bc0-488b-9b03-f0cac400baec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped MCP server process.\n"
     ]
    }
   ],
   "source": [
    "server_process.terminate()\n",
    "print(\"Stopped MCP server process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80543fa-6463-411d-a2a6-d0df7eeeff38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
